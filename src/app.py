import tkinter as tk
from tkinter import ttk, filedialog
import sounddevice as sd
import numpy as np
import threading
import os
import datetime
import queue
import time

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
import torch
import torch.nn as nn
import librosa

# –ö–û–ù–°–¢–ê–ù–¢–´ –ò –§–£–ù–ö–¶–ò–ò –ú–û–î–ï–õ–ò 
RUSSIAN_ALPHABET = "_–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è "
BLANK_CHAR = '_'
char_map = {char: idx for idx, char in enumerate(RUSSIAN_ALPHABET)}
index_map = {idx: char for char, idx in char_map.items()}

def text_to_int(text, char_map):
    text = text.lower()
    return [char_map[char] for char in text if char in char_map]

def int_to_text(indices, index_map, blank_char=BLANK_CHAR):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ç–µ–∫—Å—Ç, —É–±–∏—Ä–∞—è CTC-–ø—É—Å—Ç—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø–æ–≤—Ç–æ—Ä—ã."""

    text = ""
    blank_idx = char_map.get(blank_char, -1)
    last_idx = -1
    for idx in indices:
        if idx == last_idx: 
            continue
        if idx == blank_idx:
            last_idx = idx
            continue
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –≤ –∫–∞—Ä—Ç–µ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
        if idx in index_map:
            text += index_map[idx]
        last_idx = idx
    text = ' '.join(text.split())
    return text

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥-–º–µ–ª-—Å–ø–µ—Ç—Ä–æ–≥—Ä–∞–º–º—ã
def preprocess_buffer(audio_chunk: np.ndarray, sample_rate=16000, n_mels=80, n_fft=400, hop_length=160):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç NumPy –º–∞—Å—Å–∏–≤ –∞—É–¥–∏–æ –≤ –ª–æ–≥-–º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É (F, T)."""
    # –û–∂–∏–¥–∞–µ–º, —á—Ç–æ audio_chunk —É–∂–µ –∏–º–µ–µ—Ç –Ω—É–∂–Ω—É—é sample_rate (16000)
    # –∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—É—é –¥–ª–∏–Ω—É (>= n_fft), —Ç–∞–∫ –∫–∞–∫ –æ–Ω —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∏–∑ –±—É—Ñ–µ—Ä–∞

    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ float32, –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç librosa
    if audio_chunk.dtype != np.float32:
        audio_chunk = audio_chunk.astype(np.float32)

    # –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–∏—à–∏–Ω–æ–π –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (—Ö–æ—Ç—è –∏–∑ –±—É—Ñ–µ—Ä–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –Ω—É–∂–Ω–∞—è –¥–ª–∏–Ω–∞)
    if len(audio_chunk) < n_fft:
        padding_needed = n_fft - len(audio_chunk)
        audio_chunk = np.pad(audio_chunk, (0, padding_needed), mode='constant', constant_values=0)

    try:
        mel_spectrogram = librosa.feature.melspectrogram(y=audio_chunk, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fmax=8000)
    except Exception as e:
         print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ melspectrogram –∏–∑ –±—É—Ñ–µ—Ä–∞: {e}")
         return None
    if np.max(mel_spectrogram) < 1e-10: return None # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–∏—à–∏–Ω—É

    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)
    mean = np.mean(log_mel_spectrogram); std = np.std(log_mel_spectrogram)
    
    if std < 1e-6: 
        return None
    
    log_mel_spectrogram = (log_mel_spectrogram - mean) / (std + 1e-6)
    
    return torch.tensor(log_mel_spectrogram, dtype=torch.float32) # (F, T)

# ASR_CTC_Model 
class ASR_CTC_Model(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.15):
        super(ASR_CTC_Model, self).__init__()
        # –°–ª–æ–∏ Conv2d –æ–∂–∏–¥–∞—é—Ç –≤—Ö–æ–¥ (B, C, H, W) –∏–ª–∏ (B, C, F, T)
        self.conv_layers = nn.Sequential(
            # –í—Ö–æ–¥: (B, 1, F=input_dim, T)
            nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), # -> (B, 32, F/2, T/2)
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), # -> (B, 32, F/4, T/4)
            nn.ReLU(),
            nn.BatchNorm2d(32)
        )
    
        # –†–∞—Å—á–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è LSTM
        lstm_input_dim = 32 * (input_dim // 4) # –ö–∞–Ω–∞–ª—ã * (F —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤ 2 —Ä–∞–∑–∞ –¥–≤–∞–∂–¥—ã (–∏–∑-–∑–∞ stride[0]=2))

        # Dropout —Å–ª–æ–π
        self.conv_dropout = nn.Dropout(dropout)

        self.lstm = nn.LSTM(
            lstm_input_dim,
            hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            bidirectional=True,
            dropout=dropout if num_layers > 1 else 0 # Dropout –º–µ–∂–¥—É —Å–ª–æ—è–º–∏ LSTM
        )

        self.fc_dropout = nn.Dropout(dropout)

        self.fc = nn.Linear(hidden_dim * 2, output_dim) # Bidirectional -> *2

    def forward(self, x):
        # x: (batch, F, T) - –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç DataLoader
        x = x.unsqueeze(1) # -> (B, 1, F, T) - –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª –¥–ª—è Conv2d
        x = self.conv_layers(x) # -> (B, 32, F/4, T/4)

        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è LSTM: (batch, T', features)
        batch_size, channels, F_prime, T_prime = x.shape
        x = x.permute(0, 3, 1, 2) # -> (B, T', C, F') -> T'=T/4, F'=F/4
        x = x.reshape(batch_size, T_prime, channels * F_prime) # -> (B, T', 32*F/4)

        #  Dropout –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–æ–∫
        x = self.conv_dropout(x)

        x, _ = self.lstm(x) # -> (B, T', H*2)

        # Dropout –ø–µ—Ä–µ–¥ FC
        x = self.fc_dropout(x)

        x = self.fc(x) # -> (B, T', Output)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º LogSoftmax –¥–ª—è CTC Loss
        # CTC –æ–∂–∏–¥–∞–µ—Ç (T, N, C), –≥–¥–µ N=batch_size, T=–¥–ª–∏–Ω–∞ –ø–æ—Å–ª., C=–∫–ª–∞—Å—Å—ã
        x = nn.functional.log_softmax(x, dim=2) # -> (B, T', Output)
        return x

    def get_output_lengths(self, input_lengths_T): # –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –¥–ª–∏–Ω—ã –ø–æ –æ—Å–∏ T
        """ –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–ª–∏–Ω—É –í–´–•–û–î–ê –ø–æ –æ—Å–∏ T –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–æ–∫ """
        lengths = input_lengths_T

        # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–æ –æ—Å–∏ T –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è stride[1] –¥–ª—è Conv2d –ø—Ä–∏ –≤—Ö–æ–¥–µ (B, C, F, T)
        
        # –ü–µ—Ä–≤—ã–π Conv: stride=(2, 2) -> stride[1]=2
        if isinstance(self.conv_layers[0], nn.Conv2d) and self.conv_layers[0].stride[1] > 1:
             lengths = torch.div(lengths - 1, self.conv_layers[0].stride[1], rounding_mode='floor') + 1
        
        # –í—Ç–æ—Ä–æ–π Conv: stride=(2, 2) -> stride[1]=2
        if isinstance(self.conv_layers[3], nn.Conv2d) and self.conv_layers[3].stride[1] > 1:
             lengths = torch.div(lengths - 1, self.conv_layers[3].stride[1], rounding_mode='floor') + 1

        # –ò—Ç–æ–≥–æ T_out = T_in / 4
        return lengths

# –ü–ê–†–ê–ú–ï–¢–†–´ –ú–û–î–ï–õ–ò –ò –ü–£–¢–¨
INPUT_DIM = 80
HIDDEN_DIM = 768 # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –≤–∞—à–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
OUTPUT_DIM = len(RUSSIAN_ALPHABET)
NUM_LAYERS = 4
DROPOUT = 0.3    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –≤–∞—à–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
MODEL_LOAD_PATH = "C:/Users/danya/Downloads/asr_ctc_model_epoch11_WER55.pth" # –ü—Ä–∏–º–µ—Ä

# –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –£–°–¢–†–û–ô–°–¢–í–ê
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {device}")

# –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò 
print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
model = ASR_CTC_Model(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, NUM_LAYERS, DROPOUT).to(device)
try:
    # map_location=device –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    model.load_state_dict(torch.load(MODEL_LOAD_PATH, map_location=device))
    model.eval() # <--- –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
    print("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏.")
except FileNotFoundError:
    print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {MODEL_LOAD_PATH}")
    print("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –±—É–¥–µ—Ç –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞.")
    model = None # –°—Ç–∞–≤–∏–º –º–æ–¥–µ–ª—å –≤ None, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫ –¥–∞–ª—å—à–µ
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
    model = None

# –§—É–Ω–∫—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —á–∞–Ω–∫–∞
@torch.no_grad() # –û—Ç–∫–ª—é—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
def transcribe_chunk(audio_chunk, model, device, index_map):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —á–∞–Ω–∫ –∞—É–¥–∏–æ (NumPy array)."""
    if model is None: # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å
        return "[–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞]"

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞ -> –¢–µ–Ω–∑–æ—Ä (F, T) –Ω–∞ CPU
    input_features = preprocess_buffer(audio_chunk) # sample_rate –∏ –¥—Ä. –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ—Ä—É—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    if input_features is None:
        # print("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å.")
        return "[–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏]"

    # –ü–µ—Ä–µ–Ω–æ—Å –Ω–∞ device –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ batch-–∏–∑–º–µ—Ä–µ–Ω–∏—è -> (1, F, T)
    input_tensor = input_features.unsqueeze(0).to(device)
    # –î–ª–∏–Ω–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (T) –¥–ª—è get_output_lengths
    input_length_T = torch.tensor([input_features.shape[1]], dtype=torch.long).to(device)

    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏
        outputs = model(input_tensor) # (1, T_out, C)
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –≤—ã—Ö–æ–¥–∞
        output_lengths = model.get_output_lengths(input_length_T) # (1)

        if output_lengths[0] <= 0:
            # print("–ù—É–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏.")
            return "" # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞, –µ—Å–ª–∏ –≤—ã—Ö–æ–¥ –Ω—É–ª–µ–≤–æ–π

        # Greedy –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        pred_indices = torch.argmax(outputs, dim=2).squeeze(0) # (T_out)
        pred_indices_cpu = pred_indices[:output_lengths[0]].cpu().tolist() # –û–±—Ä–µ–∑–∞–µ–º –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ CPU

        decoded_text = int_to_text(pred_indices_cpu, index_map)
        return decoded_text

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–∏: {e}")
        return "[–û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞]"

# –ö–ª–∞—Å—Å GUI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
class AudioApp:
    def __init__(self, root, loaded_model):
        self.root = root
        self.root.title("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Ä–µ—á–∏")
        self.model = loaded_model # –ú–æ–¥–µ–ª—å
        self.device = device      # CPU –∏–ª–∏ GPU

        #  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø–∏—Å–∏
        self.samplerate = 16000
        self.channels = 1
        self.blocksize = 1024 # –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –æ—Ç sounddevice
        self.seconds_per_chunk = 1 # –°–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        self.samples_per_chunk = self.samplerate * self.seconds_per_chunk

        # GUI —ç–ª–µ–º–µ–Ω—Ç—ã
        self.save_directory = os.getcwd()

        top_frame = ttk.Frame(root)                 # –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä—É–ø–ø–∏—Ä—É—é—â–µ–≥–æ –≤–∏–¥–∂–µ—Ç–∞
        top_frame.pack(fill=tk.X, padx=10, pady=5)  # –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ top_frame —Å root –æ—Ç—Å—Ç—É–ø—ã 10 –∏ 5 –∏ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–Ω–∏–µ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏

        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–¥–ø–∏—Å–∏ –ø–æ –ø—Ä–∞–≤–æ–º—É –∫—Ä–∞—é top_frame
        self.dir_label = ttk.Label(top_frame, text="üìÅ –ü–∞–ø–∫–∞: " + self.save_directory, anchor="e")
        self.dir_label.pack(side=tk.RIGHT)

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ –≤ –ø—Ä–∞–≤–æ–º –∫—Ä–∞—é
        self.dir_button = ttk.Button(top_frame, text="–í—ã–±—Ä–∞—Ç—å –ø–∞–ø–∫—É", command=self.choose_directory)
        self.dir_button.pack(side=tk.RIGHT, padx=5)

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ —Å –æ—Ç—Å—Ç—É–ø–æ–º –≤–Ω–∏–∑ –Ω–∞ 10
        self.record_button = ttk.Button(root, text="–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å", command=self.toggle_recording)
        self.record_button.pack(pady=10)

        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –ø–æ–¥ –∫–Ω–æ–ø–∫–æ–π –∑–∞–ø–∏—Å–∏
        self.recording_indicator = ttk.Label(root, text="", foreground="red", font=("Arial", 10, "bold"))
        self.recording_indicator.pack()
        
        # –û–±–ª–∞—Å—Ç—å –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        self.transcription_text = tk.Text(root, height=10, width=60, wrap=tk.WORD, state=tk.DISABLED, font=("Arial", 10))
        self.transcription_text.pack(pady=10, padx=10, fill=tk.BOTH, expand=True)
        
        # –î–æ–±–∞–≤–∏–º –ø—Ä–æ–∫—Ä—É—Ç–∫—É —Ç–µ–∫—Å—Ç–∞
        scrollbar = ttk.Scrollbar(self.transcription_text, command=self.transcription_text.yview)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.transcription_text['yscrollcommand'] = scrollbar.set

        # –û—á–µ—Ä–µ–¥—å –∏ –±—É—Ñ–µ—Ä
        self.audio_queue = queue.Queue()
        self.internal_buffer = [] # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –∑–¥–µ—Å—å –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.recording_thread = None
        self.processing_thread = None
        self.is_running = False                     # –§–ª–∞–≥ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –∑–∞–ø–∏—Å–∏
        self.stop_processing = threading.Event()    # –°–æ–±—ã—Ç–∏–µ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
        self.start_processing_thread()

    def choose_directory(self):
        folder = filedialog.askdirectory()
        if folder: 
            self.save_directory = folder
            self.dir_label.config(text="üìÅ –ü–∞–ø–∫–∞: " + self.save_directory)

    def audio_callback(self, indata: np.ndarray, frames: int, time, status: sd.CallbackFlags):
        """Callback —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç sounddevice."""
        if status: 
            print(status, flush=True) # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç—É—Å, –µ—Å–ª–∏ –µ—Å—Ç—å

        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä –∏ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª
        self.internal_buffer.append(indata[:, 0].copy())

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—ç–º–ø–ª–æ–≤ (shape[0] —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å)
        total_samples_in_buffer = sum(chunk.shape[0] for chunk in self.internal_buffer)

        if total_samples_in_buffer >= self.samples_per_chunk:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —á–∞—Å—Ç–∏ –±—É—Ñ–µ—Ä–∞ –≤ –æ–¥–∏–Ω –¥–ª–∏–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
            concatenated_audio = np.concatenate(self.internal_buffer, axis=0)

            # –ë–µ—Ä–µ–º —Ä–æ–≤–Ω–æ samples_per_chunk
            chunk_to_process = concatenated_audio[:self.samples_per_chunk]
            # –û—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –±—É—Ñ–µ—Ä
            remaining_audio = concatenated_audio[self.samples_per_chunk:]

            # –ö–ª–∞–¥–µ–º –≥–æ—Ç–æ–≤—ã–π —á–∞–Ω–∫ –≤ –æ—á–µ—Ä–µ–¥—å
            self.audio_queue.put(chunk_to_process)

            # –û–±–Ω–æ–≤–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –±—É—Ñ–µ—Ä
            if remaining_audio.size > 0:
                self.internal_buffer = [remaining_audio]
            else:
                self.internal_buffer = []

    def toggle_recording(self):
        if not self.is_running:
            self.start_recording()
        else: 
            self.stop_recording()

    def start_recording(self):
        if self.is_running:
            return # –£–∂–µ –∑–∞–ø—É—â–µ–Ω–æ
        
        print("–ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏...")

        self.is_running = True
        self.internal_buffer = [] # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
        self.record_button.config(text="–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å")
        self.recording_indicator.config(text="‚óè –ò–¥—ë—Ç –∑–∞–ø–∏—Å—å...")
        self.clear_transcription() # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ –ø–æ—Ç–æ–∫–µ –∑–∞–ø–∏—Å–∏
        def _record_thread():
            try:
                # –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ—Ç–æ–∫–∞
                with sd.InputStream(callback=self.audio_callback,
                                    samplerate=self.samplerate,
                                    channels=self.channels,
                                    blocksize=self.blocksize, # –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –¥–ª—è callback
                                    dtype='float32'): # –ò—Å–ø–æ–ª—å–∑—É–µ–º float32
                    while self.is_running:
                        sd.sleep(100) # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å CPU
                print("–ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ –∑–∞–≤–µ—Ä—à–µ–Ω.")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –∑–∞–ø–∏—Å–∏: {e}")
                self.root.after(0, self.stop_recording) # –í—ã–∑—ã–≤–∞–µ–º stop_recording –≤ –≥–ª–∞–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏
        self.recording_thread = threading.Thread(target=_record_thread, daemon=True)
        self.recording_thread.start()

    def stop_recording(self):
        if not self.is_running: return # –£–∂–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
        print("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...")
        self.is_running = False # –°–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫—É –∑–∞–ø–∏—Å–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –∑–∞–ø–∏—Å–∏ (—Å —Ç–∞–π–º–∞—É—Ç–æ–º)
        if self.recording_thread is not None:
             self.recording_thread.join(timeout=1.0) # –ñ–¥–µ–º –Ω–µ –±–æ–ª–µ–µ 1 —Å–µ–∫—É–Ω–¥—ã
             if self.recording_thread.is_alive():
                 print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –≤–æ–≤—Ä–µ–º—è.")
             self.recording_thread = None

        self.save_transcription()

        self.record_button.config(text="–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å")
        self.recording_indicator.config(text="")
        print("–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
        # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö –≤ internal_buffer, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ

    def save_transcription(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—è –≤ —Ñ–∞–π–ª."""
        full_text = self.transcription_text.get("1.0", tk.END).strip() # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        
        if not full_text:
            print("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")
            self.dir_label.config(text="–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")
            return

        filename = datetime.datetime.now().strftime("transcription_%d_%m_%Y_%H-%M-%S.txt")

        path = os.path.join(self.save_directory, filename)

        try:
            with open(path, 'w', encoding='utf-8') as f:
                f.write(full_text)
            print(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {path}")

            # basename –¥–ª—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ UI
            self.dir_label.config(text=f"‚úÖ –¢–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {os.path.basename(path)}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            self.dir_label.config(text="‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞!")

    def start_processing_thread(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏."""
        self.stop_processing.clear() # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        self.processing_thread = threading.Thread(target=self.process_audio_from_queue, daemon=True)
        self.processing_thread.start()

    def process_audio_from_queue(self):
        """–ü–æ—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –±–µ—Ä–µ—Ç —á–∞–Ω–∫–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∏—Ö."""
        print("–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏ –∑–∞–ø—É—â–µ–Ω.")
        while not self.stop_processing.is_set():
            try:
                # –ñ–¥–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (—Å —Ç–∞–π–º–∞—É—Ç–æ–º, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –ø–æ–¥–æ–∂–¥–∞—Ç—å –¥–∞–Ω–Ω—ã–µ)
                audio_chunk = self.audio_queue.get(timeout=0.5) # –¢–∞–π–º–∞—É—Ç 0.5 —Å–µ–∫

                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
                #start_time = time.time()
                transcribed_text = transcribe_chunk(audio_chunk, self.model, self.device, index_map)
                #end_time = time.time()
                # print(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —á–∞–Ω–∫–∞ ({end_time - start_time:.2f} —Å–µ–∫): '{transcribed_text}'")

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ GUI
                if transcribed_text and transcribed_text not in ["[–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏]", "[–û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞]", "[–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞]"]:
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ –ø–æ–ª–µ —Å –ø—Ä–æ–∫—Ä—É—Ç–∫–æ–π —á–µ—Ä–µ–∑ 0 —Å–µ–∫—É–Ω–¥
                    self.root.after(0, self.update_transcription, transcribed_text + " ") # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª

            except queue.Empty:
                # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∂–¥–∞—Ç—å
                continue
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                time.sleep(0.4) # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        print("–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

    def update_transcription(self, text_to_add):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –∏–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞."""
        self.transcription_text.config(state=tk.NORMAL) # –†–∞–∑—Ä–µ—à–∞–µ–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.transcription_text.insert(tk.END, text_to_add)
        self.transcription_text.see(tk.END) # –ê–≤—Ç–æ–ø—Ä–æ–∫—Ä—É—Ç–∫–∞ –≤–Ω–∏–∑
        self.transcription_text.config(state=tk.DISABLED) # –°–Ω–æ–≤–∞ –∑–∞–ø—Ä–µ—â–∞–µ–º

    def clear_transcription(self):
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ."""
        self.transcription_text.config(state=tk.NORMAL)
        self.transcription_text.delete('1.0', tk.END)
        self.transcription_text.config(state=tk.DISABLED)

    def on_closing(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –æ–∫–Ω–∞."""
        print("–ó–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
        if self.is_running:
            self.stop_recording() # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å, –µ—Å–ª–∏ –∏–¥–µ—Ç
        self.stop_processing.set() # –°–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
        if self.processing_thread is not None:
            self.processing_thread.join(timeout=1.0) # –ñ–¥–µ–º –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.root.destroy() # –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ–∫–Ω–æ


# --- –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
if __name__ == "__main__":
    if model is None:
        print("–ú–æ–¥–µ–ª—å –Ω–µ –±—ã–ª–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –∑–∞–Ω–æ–≤–æ, —É–∫–∞–∑–∞–≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å.")
    else:
        root = tk.Tk()
        app = AudioApp(root, model) # –ü–µ—Ä–µ–¥–∞–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
        root.protocol("WM_DELETE_WINDOW", app.on_closing) # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –æ–∫–Ω–∞
        root.mainloop()