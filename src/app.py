import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import sounddevice as sd
import numpy as np
import threading
import os
import datetime
import queue
import time

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
import torch
import torch.nn as nn
import librosa
from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor, WhisperForConditionalGeneration

# –ö–û–ù–°–¢–ê–ù–¢–´ –ò –§–£–ù–ö–¶–ò–ò –ú–û–î–ï–õ–ò 
RUSSIAN_ALPHABET = "_–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è "
BLANK_CHAR = '_'
char_map = {char: idx for idx, char in enumerate(RUSSIAN_ALPHABET)}
index_map = {idx: char for char, idx in char_map.items()}

def text_to_int(text, char_map):
    text = text.lower()
    return [char_map[char] for char in text if char in char_map]

def int_to_text(indices, index_map, blank_char=BLANK_CHAR):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ç–µ–∫—Å—Ç, —É–±–∏—Ä–∞—è CTC-–ø—É—Å—Ç—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø–æ–≤—Ç–æ—Ä—ã."""

    text = ""
    blank_idx = char_map.get(blank_char, -1)
    last_idx = -1
    for idx in indices:
        if idx == last_idx: 
            continue
        if idx == blank_idx:
            last_idx = idx
            continue
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –≤ –∫–∞—Ä—Ç–µ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
        if idx in index_map:
            text += index_map[idx]
        last_idx = idx
    text = ' '.join(text.split())
    return text

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥-–º–µ–ª-—Å–ø–µ—Ç—Ä–æ–≥—Ä–∞–º–º—ã
def preprocess_buffer(audio_chunk: np.ndarray, sample_rate=16000, n_mels=80, n_fft=400, hop_length=160):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç NumPy –º–∞—Å—Å–∏–≤ –∞—É–¥–∏–æ –≤ –ª–æ–≥-–º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É (F, T)."""

    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ float32, –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç librosa
    if audio_chunk.dtype != np.float32:
        audio_chunk = audio_chunk.astype(np.float32)

    # –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–∏—à–∏–Ω–æ–π –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (—Ö–æ—Ç—è –∏–∑ –±—É—Ñ–µ—Ä–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –Ω—É–∂–Ω–∞—è –¥–ª–∏–Ω–∞)
    if len(audio_chunk) < n_fft:
        padding_needed = n_fft - len(audio_chunk)
        audio_chunk = np.pad(audio_chunk, (0, padding_needed), mode='constant', constant_values=0)

    # import matplotlib.pyplot as plt


    # # –ü–æ—Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –∞–º–ø–ª–∏—Ç—É–¥–Ω—ã—Ö –æ—Ç—Å—á—ë—Ç–æ–≤
    # plt.figure(figsize=(10, 4))
    # plt.plot(audio_chunk)
    # plt.title("–ê–º–ø–ª–∏—Ç—É–¥–Ω—ã–µ –æ—Ç—Å—á—ë—Ç—ã –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–∞")
    # plt.xlabel("–ù–æ–º–µ—Ä –æ—Ç—Å—á—ë—Ç–∞")
    # plt.ylabel("–ê–º–ø–ª–∏—Ç—É–¥–∞")
    # plt.grid(True)
    # plt.tight_layout()
    # plt.show()

    try:
        mel_spectrogram = librosa.feature.melspectrogram(y=audio_chunk, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fmax=8000)
    except Exception as e:
         print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ melspectrogram –∏–∑ –±—É—Ñ–µ—Ä–∞: {e}")
         return None
    
    if np.max(mel_spectrogram) < 1e-10: return None # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–∏—à–∏–Ω—É

    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)

    mean = np.mean(log_mel_spectrogram)
    std = np.std(log_mel_spectrogram)
    
    if std < 1e-6: 
        return None
    
    log_mel_spectrogram = (log_mel_spectrogram - mean) / (std + 1e-6)
    
    return torch.tensor(log_mel_spectrogram, dtype=torch.float32) # (F, T)

# ASR_CTC_Model 
class ASR_CTC_Model(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.15):
        super(ASR_CTC_Model, self).__init__()
        # –°–ª–æ–∏ Conv2d –æ–∂–∏–¥–∞—é—Ç –≤—Ö–æ–¥ (B, C, H, W) –∏–ª–∏ (B, C, F, T)
        self.conv_layers = nn.Sequential(
            # –í—Ö–æ–¥: (B, 1, F=input_dim, T)
            nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), # -> (B, 32, F/2, T/2)
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), # -> (B, 32, F/4, T/4)
            nn.ReLU(),
            nn.BatchNorm2d(32)
        )
    
        # –†–∞—Å—á–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è LSTM
        lstm_input_dim = 32 * (input_dim // 4) # –ö–∞–Ω–∞–ª—ã * (F —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤ 2 —Ä–∞–∑–∞ –¥–≤–∞–∂–¥—ã (–∏–∑-–∑–∞ stride[0]=2))

        # Dropout —Å–ª–æ–π
        self.conv_dropout = nn.Dropout(dropout)

        self.lstm = nn.LSTM(
            lstm_input_dim,
            hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            bidirectional=True,
            dropout=dropout if num_layers > 1 else 0 # Dropout –º–µ–∂–¥—É —Å–ª–æ—è–º–∏ LSTM
        )

        self.fc_dropout = nn.Dropout(dropout)

        self.fc = nn.Linear(hidden_dim * 2, output_dim) # Bidirectional -> *2

    def forward(self, x):
        # x: (batch, F, T) - –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç DataLoader
        x = x.unsqueeze(1) # -> (B, 1, F, T) - –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª –¥–ª—è Conv2d
        x = self.conv_layers(x) # -> (B, 32, F/4, T/4)

        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è LSTM: (batch, T', features)
        batch_size, channels, F_prime, T_prime = x.shape
        x = x.permute(0, 3, 1, 2) # -> (B, T', C, F') -> T'=T/4, F'=F/4
        x = x.reshape(batch_size, T_prime, channels * F_prime) # -> (B, T', 32*F/4)

        #  Dropout –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–æ–∫
        x = self.conv_dropout(x)

        x, _ = self.lstm(x) # -> (B, T', H*2)

        # Dropout –ø–µ—Ä–µ–¥ FC
        x = self.fc_dropout(x)

        x = self.fc(x) # -> (B, T', Output)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º LogSoftmax –¥–ª—è CTC Loss
        # CTC –æ–∂–∏–¥–∞–µ—Ç (T, N, C), –≥–¥–µ N=batch_size, T=–¥–ª–∏–Ω–∞ –ø–æ—Å–ª., C=–∫–ª–∞—Å—Å—ã
        x = nn.functional.log_softmax(x, dim=2) # -> (B, T', Output)
        return x

    def get_output_lengths(self, input_lengths_T): # –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –¥–ª–∏–Ω—ã –ø–æ –æ—Å–∏ T
        """ –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–ª–∏–Ω—É –í–´–•–û–î–ê –ø–æ –æ—Å–∏ T –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–æ–∫ """
        lengths = input_lengths_T

        # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–æ –æ—Å–∏ T –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è stride[1] –¥–ª—è Conv2d –ø—Ä–∏ –≤—Ö–æ–¥–µ (B, C, F, T)
        
        # –ü–µ—Ä–≤—ã–π Conv: stride=(2, 2) -> stride[1]=2
        if isinstance(self.conv_layers[0], nn.Conv2d) and self.conv_layers[0].stride[1] > 1:
             lengths = torch.div(lengths - 1, self.conv_layers[0].stride[1], rounding_mode='floor') + 1
        
        # –í—Ç–æ—Ä–æ–π Conv: stride=(2, 2) -> stride[1]=2
        if isinstance(self.conv_layers[3], nn.Conv2d) and self.conv_layers[3].stride[1] > 1:
             lengths = torch.div(lengths - 1, self.conv_layers[3].stride[1], rounding_mode='floor') + 1

        # –ò—Ç–æ–≥–æ T_out = T_in / 4
        return lengths

# –ü–ê–†–ê–ú–ï–¢–†–´ –ú–û–î–ï–õ–ò –ò –ü–£–¢–¨
INPUT_DIM = 80
HIDDEN_DIM = 1024 # –ß–∏—Å–ª–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Å–∫—Ä—ã—Ç–æ–º —Å–ª–æ–µ LSTM
OUTPUT_DIM = len(RUSSIAN_ALPHABET)
NUM_LAYERS = 3    # –ß–∏—Å–ª–æ —Å–ª–æ–µ–≤ LSTM
DROPOUT = 0.3   
#MODEL_LOAD_PATH = "D:/models/1024_3layer_all_datasets/all_data_1024_3layer_epoch9_WER29.26.pth"
MODEL_LOAD_PATH = "D:/models/ASR_CTC_MODEL_1024_3layer_GOLOS, common voice, sova ai, librispeech/gslc_asr_ctc_model_1024_3layer_epoch20_WER11.60.pth" # –ü—Ä–∏–º–µ—Ä

# –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –£–°–¢–†–û–ô–°–¢–í–ê
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {device}")

# –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò 
print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
model = ASR_CTC_Model(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, NUM_LAYERS, DROPOUT).to(device)
try:
    # map_location=device –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    model.load_state_dict(torch.load(MODEL_LOAD_PATH, map_location=device))
    model.eval() # <--- –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
    print("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏.")
except FileNotFoundError:
    print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {MODEL_LOAD_PATH}")
    print("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –±—É–¥–µ—Ç –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞.")
    model = None # –°—Ç–∞–≤–∏–º –º–æ–¥–µ–ª—å –≤ None, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫ –¥–∞–ª—å—à–µ
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
    model = None

# –§—É–Ω–∫—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —á–∞–Ω–∫–∞
@torch.no_grad() # –û—Ç–∫–ª—é—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
def transcribe_chunk(audio_chunk, model, device, index_map):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —á–∞–Ω–∫ –∞—É–¥–∏–æ (NumPy array)."""
    if model is None: # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å
        return "[–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞]"

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞ -> –¢–µ–Ω–∑–æ—Ä (F, T) –Ω–∞ CPU
    input_features = preprocess_buffer(audio_chunk) # sample_rate –∏ –¥—Ä. –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ—Ä—É—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    if input_features is None:
        # print("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å.")
        return "[–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏]"

    # –ü–µ—Ä–µ–Ω–æ—Å –Ω–∞ device –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ batch-–∏–∑–º–µ—Ä–µ–Ω–∏—è -> (1, F, T)
    input_tensor = input_features.unsqueeze(0).to(device)
    # –î–ª–∏–Ω–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (T) –¥–ª—è get_output_lengths
    input_length_T = torch.tensor([input_features.shape[1]], dtype=torch.long).to(device)

    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏
        outputs = model(input_tensor) # (1, T_out, C)
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –≤—ã—Ö–æ–¥–∞
        output_lengths = model.get_output_lengths(input_length_T) # (1)

        if output_lengths[0] <= 0:
            # print("–ù—É–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏.")
            return "" # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞, –µ—Å–ª–∏ –≤—ã—Ö–æ–¥ –Ω—É–ª–µ–≤–æ–π

        
        # Greedy –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        pred_indices = torch.argmax(outputs, dim=2).squeeze(0) # (T_out)
        pred_indices_cpu = pred_indices[:output_lengths[0]].cpu().tolist() # –û–±—Ä–µ–∑–∞–µ–º –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ CPU
        decoded_text = int_to_text(pred_indices_cpu, index_map)

        return decoded_text

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–∏: {e}")
        return "[–û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞]"

QUEUE_END_MARKER = object()

# –ö–ª–∞—Å—Å GUI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
class AudioApp:
    def __init__(self, root, loaded_model, feauture_extractor=None, whisper_model=None, tokenizer=None):
        self.root = root
        self.root.title("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Ä–µ—á–∏")
        self.model = loaded_model # –ú–æ–¥–µ–ª—å –¥–ª—è –º–æ–µ–π
        self.whisper_feature_extractor = feauture_extractor
        self.whisper_model = whisper_model
        self.whisper_tokenizer = tokenizer
        self.device = device      # CPU –∏–ª–∏ GPU

        #  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø–∏—Å–∏
        self.samplerate = 16000
        self.channels = 1
        self.blocksize = 1024 # –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –æ—Ç sounddevice
        self.seconds_per_chunk = 5 # –°–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        self.samples_per_chunk = self.samplerate * self.seconds_per_chunk

        # GUI —ç–ª–µ–º–µ–Ω—Ç—ã
        self.save_directory = os.getcwd()

        top_frame = ttk.Frame(root)                 # –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä—É–ø–ø–∏—Ä—É—é—â–µ–≥–æ –≤–∏–¥–∂–µ—Ç–∞
        top_frame.pack(fill=tk.X, padx=10, pady=5)  # –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ top_frame —Å root –æ—Ç—Å—Ç—É–ø—ã 10 –∏ 5 –∏ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–Ω–∏–µ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏

        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–¥–ø–∏—Å–∏ –ø–æ –ø—Ä–∞–≤–æ–º—É –∫—Ä–∞—é top_frame
        self.dir_label = ttk.Label(top_frame, text="üìÅ –ü–∞–ø–∫–∞: " + self.save_directory, anchor="e")
        self.dir_label.pack(side=tk.RIGHT)

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ –≤ –ø—Ä–∞–≤–æ–º –∫—Ä–∞—é
        self.dir_button = ttk.Button(top_frame, text="–í—ã–±—Ä–∞—Ç—å –ø–∞–ø–∫—É", command=self.choose_directory)
        self.dir_button.pack(side=tk.RIGHT, padx=5)

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏ —Å –æ—Ç—Å—Ç—É–ø–æ–º –≤–Ω–∏–∑ –Ω–∞ 10
        self.record_button = ttk.Button(root, text="–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å", command=self.toggle_recording)
        self.record_button.pack(pady=10)

        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –ø–æ–¥ –∫–Ω–æ–ø–∫–æ–π –∑–∞–ø–∏—Å–∏
        self.recording_indicator = ttk.Label(root, text="", foreground="red", font=("Arial", 10, "bold"))
        self.recording_indicator.pack()
        
        # –û–±–ª–∞—Å—Ç—å –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        self.transcription_text = tk.Text(root, height=10, width=60, wrap=tk.WORD, state=tk.DISABLED, font=("Arial", 10))
        self.transcription_text.pack(pady=10, padx=10, fill=tk.BOTH, expand=True)
        
        # –î–æ–±–∞–≤–∏–º –ø—Ä–æ–∫—Ä—É—Ç–∫—É —Ç–µ–∫—Å—Ç–∞
        scrollbar = ttk.Scrollbar(self.transcription_text, command=self.transcription_text.yview)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.transcription_text['yscrollcommand'] = scrollbar.set

        try:
            default_input = sd.default.device[0]  # –∏–Ω–¥–µ–∫—Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤–≤–æ–¥–∞
            if default_input is None or default_input < 0:
                messagebox.showwarning("–í–Ω–∏–º–∞–Ω–∏–µ", "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            else:
                messagebox.showinfo("–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ", "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ–¥–∫–ª—é—á–µ–Ω!")
        except:
            messagebox.showwarning("–í–Ω–∏–º–∞–Ω–∏–µ", "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω!")

        # –û—á–µ—Ä–µ–¥—å –∏ –±—É—Ñ–µ—Ä
        self.audio_queue = queue.Queue()
        self.transcription_queue = queue.Queue()
        self.internal_buffer = [] # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –∑–¥–µ—Å—å –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.recording_thread = None
        self.processing_thread = None
        self.is_recording = False                   # –§–ª–∞–≥ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –∑–∞–ø–∏—Å–∏
        self.gui_update_timer = None                # –î–ª—è —Ç–∞–π–º–µ—Ä–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è GUI
        self.gui_update_ms = 100                    # –ö–∞–∫ —á–∞—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –æ—á–µ—Ä–µ–¥—å —Ç–µ–∫—Å—Ç–∞ (–º—Å)

    def choose_directory(self):
        folder = filedialog.askdirectory()
        if folder: 
            self.save_directory = folder
            self.dir_label.config(text="üìÅ –ü–∞–ø–∫–∞: " + self.save_directory)

    def audio_callback(self, indata: np.ndarray, frames: int, time, status: sd.CallbackFlags):
        """Callback —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç sounddevice."""
        if status: print(status, flush=True) # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç—É—Å, –µ—Å–ª–∏ –µ—Å—Ç—å
        if not self.is_recording: return

        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä –∏ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª
        self.internal_buffer.append(indata[:, 0].copy())

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—ç–º–ø–ª–æ–≤ (shape[0] —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å)
        total_samples_in_buffer = sum(chunk.shape[0] for chunk in self.internal_buffer)

        if total_samples_in_buffer >= self.samples_per_chunk:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —á–∞—Å—Ç–∏ –±—É—Ñ–µ—Ä–∞ –≤ –æ–¥–∏–Ω –¥–ª–∏–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
            concatenated_audio = np.concatenate(self.internal_buffer, axis=0)

            # –ë–µ—Ä–µ–º —Ä–æ–≤–Ω–æ samples_per_chunk
            chunk_to_process = concatenated_audio[:self.samples_per_chunk]
            
            # –û—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –±—É—Ñ–µ—Ä
            remaining_audio = concatenated_audio[self.samples_per_chunk:]

            # –•–≤–æ—Å—Ç –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å "–ø–∞–º—è—Ç—å—é"
            #tail_audio = chunk_to_process[-1600:]

            # –ö–ª–∞–¥–µ–º –≥–æ—Ç–æ–≤—ã–π —á–∞–Ω–∫ –≤ –æ—á–µ—Ä–µ–¥—å
            self.audio_queue.put(chunk_to_process)

            # –û–±–Ω–æ–≤–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –±—É—Ñ–µ—Ä
            if remaining_audio.size > 0:
                self.internal_buffer = [remaining_audio] #[tail_audio, remaining_audio]
            else:
                self.internal_buffer = [] #[tail_audio]

    def toggle_recording(self):
        if not self.is_recording:
            self.start_recording()
        else: 
            self.stop_recording()

    def start_recording(self):
        if self.is_recording:
            return # –£–∂–µ –∑–∞–ø—É—â–µ–Ω–æ
        
        print("–ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏...")

        self.is_recording = True
        self.internal_buffer = [] # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
        self.record_button.config(text="–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å")
        self.recording_indicator.config(text="‚óè –ò–¥—ë—Ç –∑–∞–ø–∏—Å—å...")
        self.clear_transcription() # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
        self.start_processing_thread()
        self.start_gui_updater() # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ GUI

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ –ø–æ—Ç–æ–∫–µ –∑–∞–ø–∏—Å–∏
        def _record_thread():
            try:
                # –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ—Ç–æ–∫–∞
                with sd.InputStream(callback=self.audio_callback,
                                    samplerate=self.samplerate,
                                    channels=self.channels,
                                    blocksize=self.blocksize, # –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –¥–ª—è callback
                                    dtype='float32'): # –ò—Å–ø–æ–ª—å–∑—É–µ–º float32
                    while self.is_recording:
                        sd.sleep(100) # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å CPU
                print("–ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ –∑–∞–≤–µ—Ä—à–µ–Ω.")
            except Exception as e:
                messagebox.showerror("–û—à–∏–±–∫–∞", "–ó–∞–ø–∏—Å—å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞—á–∞—Ç–∞ –±–µ–∑ –∑–∞–ø–∏—Å—ã–≤–∞—é—â–µ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞")

                print(f"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –∑–∞–ø–∏—Å–∏: {e}")
                self.root.after(0, self.stop_recording) # –í—ã–∑—ã–≤–∞–µ–º stop_recording –≤ –≥–ª–∞–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏
        self.recording_thread = threading.Thread(target=_record_thread, daemon=True)
        self.recording_thread.start()

    def stop_recording(self):
        if not self.is_recording: return # –£–∂–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
        
        print("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...")
        self.is_recording = False # –°–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫—É –∑–∞–ø–∏—Å–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –∑–∞–ø–∏—Å–∏ (—Å —Ç–∞–π–º–∞—É—Ç–æ–º)
        if self.recording_thread is not None:
            print("–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –∑–∞–ø–∏—Å–∏...")
            self.recording_thread.join(timeout=1.0) # –ñ–¥–µ–º –Ω–µ –±–æ–ª–µ–µ 1 —Å–µ–∫—É–Ω–¥
            if self.recording_thread.is_alive():
                print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏ –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –≤–æ–≤—Ä–µ–º—è.")
            self.recording_thread = None

        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –±—É—Ñ–µ—Ä –ø—É—Å—Ç
        if self.internal_buffer:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ, —á—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å
            final_chunk = np.concatenate(self.internal_buffer, axis=0)
            if final_chunk.size > 0: # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –µ—Å—Ç—å
                self.audio_queue.put(final_chunk) # –ö–ª–∞–¥–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫—É—Å–æ–∫ –≤ –æ—á–µ—Ä–µ–¥—å

            self.internal_buffer = [] # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä

        self.audio_queue.put(QUEUE_END_MARKER)

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–æ–Ω –¥–æ–ª–∂–µ–Ω –¥–æ–æ–ø—Ä–∞–±–æ—Ç–∞—Ç—å –æ—á–µ—Ä–µ–¥—å)
        if self.processing_thread is not None:
            print("–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
            self.audio_queue.join() # –î–∞–µ–º –ë–û–õ–¨–®–ï –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –¥–æ–æ–±—Ä–∞–±–æ—Ç–∫—É
            self.processing_thread.join()
            self.processing_thread = None
        print("–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

        self.stop_gui_updater()

        self.check_transcription_queue(run_once=True)
        self.root.update_idletasks()

        self.save_transcription()

        self.record_button.config(text="–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å")
        self.recording_indicator.config(text="")
        print("–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

    def save_transcription(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—è –≤ —Ñ–∞–π–ª."""
        full_text = self.transcription_text.get("1.0", tk.END).strip() # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        
        if not full_text:
            print("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")
            self.dir_label.config(text="–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")
            return

        filename = datetime.datetime.now().strftime("transcription_%d_%m_%Y_%H-%M-%S.txt")

        path = os.path.join(self.save_directory, filename)

        try:
            with open(path, 'w', encoding='utf-8') as f:
                f.write(full_text)
            print(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {path}")

            # basename –¥–ª—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ UI
            self.dir_label.config(text=f"‚úÖ –¢–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {os.path.basename(path)}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            self.dir_label.config(text="‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞!")

    def start_processing_thread(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏."""
        self.processing_thread = threading.Thread(target=self.process_audio_from_queue, daemon=True)
        self.processing_thread.start()

    def process_audio_from_queue(self):
        """–ü–æ—Ç–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –±–µ—Ä–µ—Ç —á–∞–Ω–∫–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∏—Ö."""
        print("–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏ –∑–∞–ø—É—â–µ–Ω.")

        if self.whisper_model:
            forced_decoder_ids = self.whisper_tokenizer.get_decoder_prompt_ids(language="ru", task="transcribe")

        transcribed_text = ""
        while True:
            try:
                # –ñ–¥–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (—Å —Ç–∞–π–º–∞—É—Ç–æ–º, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –ø–æ–¥–æ–∂–¥–∞—Ç—å –¥–∞–Ω–Ω—ã–µ)
                audio_chunk = self.audio_queue.get(timeout=0.5) # –¢–∞–π–º–∞—É—Ç 0.5 —Å–µ–∫

                if audio_chunk is QUEUE_END_MARKER:
                    print("–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏: –ø–æ–ª—É—á–µ–Ω –º–∞—Ä–∫–µ—Ä –∫–æ–Ω—Ü–∞.")
                    self.audio_queue.task_done()
                    break

                rms = np.sqrt(np.mean(audio_chunk**2))  # –ö–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä–µ–¥–Ω–µ–≥–æ –∫–≤–∞–¥—Ä–∞—Ç–∞ ‚Äî RMS
                db = 20 * np.log10(rms + 1e-9)          # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ dB, –¥–æ–±–∞–≤–ª—è–µ–º Œµ —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –Ω–∞ 0

                if db < -60:  
                    self.audio_queue.task_done()
                    #print("–¢–∏—à–∏–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º...")
                    #print(f"db {db}")
                    continue
                
                #print(f"–ù–µ —à—É–º db {db}")

                if self.whisper_model:
                    feature = self.whisper_feature_extractor(audio_chunk, sampling_rate=16000, language="ru", return_tensors="pt").input_features
                    feature = feature.to(self.device)

                    generated_tokens =self.whisper_model.generate(input_features=feature, forced_decoder_ids=forced_decoder_ids)
                    
                    transcribed_text = self.whisper_tokenizer.batch_decode(generated_tokens.cpu(), skip_special_tokens=True)[0]
                else:
                    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –º–æ–µ–π –º–æ–¥–µ–ª—å—é
                    transcribed_text = transcribe_chunk(audio_chunk, self.model, self.device, index_map)

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ GUI
                if transcribed_text and transcribed_text not in ["[–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏]", "[–û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞]", "[–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞]"]:
                    self.transcription_queue.put(transcribed_text)

                self.audio_queue.task_done()
            except Exception as e:
                #print(f" –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞—è: {e}")
                time.sleep(0.1) # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ    
        
        try: 
            self.audio_queue.task_done() # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–º–µ—Ç–∏—Ç—å –∑–∞–¥–∞—á—É –∫–∞–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—É—é
        except ValueError: 
            pass
        print("–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

    # –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è GUI –∏–∑ –æ—á–µ—Ä–µ–¥–∏
    def check_transcription_queue(self, run_once=False):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—á–µ—Ä–µ–¥—å —Ç–µ–∫—Å—Ç–∞ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –≤–∏–¥–∂–µ—Ç."""
        try:
            while True: # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –æ—á–µ—Ä–µ–¥–∏
                text_to_add = self.transcription_queue.get_nowait()
                self.update_transcription_widget(text_to_add + " ")
        except queue.Empty:
            pass # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è GUI –∏–∑ –æ—á–µ—Ä–µ–¥–∏: {e}")
        finally:
            # –ü–ª–∞–Ω–∏—Ä—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø—Ä–æ–≤–µ—Ä–∫—É, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—Ä–æ—à–µ–Ω –æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω—ã–π –∑–∞–ø—É—Å–∫
            # –∏ –µ—Å–ª–∏ –æ–∫–Ω–æ –µ—â–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if not run_once and self.root.winfo_exists():
                self.gui_update_timer = self.root.after(self.gui_update_ms, self.check_transcription_queue)

    def update_transcription_widget(self, text_to_add):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –∏–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞."""
        self.transcription_text.config(state=tk.NORMAL) # –†–∞–∑—Ä–µ—à–∞–µ–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.transcription_text.insert(tk.END, text_to_add)
        self.transcription_text.see(tk.END) # –ê–≤—Ç–æ–ø—Ä–æ–∫—Ä—É—Ç–∫–∞ –≤–Ω–∏–∑
        self.transcription_text.config(state=tk.DISABLED) # –°–Ω–æ–≤–∞ –∑–∞–ø—Ä–µ—â–∞–µ–º

    def clear_transcription(self):
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ."""
        self.transcription_text.config(state=tk.NORMAL)
        self.transcription_text.delete('1.0', tk.END)
        self.transcription_text.config(state=tk.DISABLED)

    # —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–π–º–µ—Ä–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è GUI 
    def start_gui_updater(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –æ—á–µ—Ä–µ–¥–∏ —Ç–µ–∫—Å—Ç–∞."""
        self.stop_gui_updater()             # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–∞–π–º–µ—Ä, –µ—Å–ª–∏ –±—ã–ª
        self.check_transcription_queue()    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—ã–π —Ä–∞–∑

    def stop_gui_updater(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –æ—á–µ—Ä–µ–¥–∏ —Ç–µ–∫—Å—Ç–∞."""
        if self.gui_update_timer is not None:
            self.root.after_cancel(self.gui_update_timer)
            self.gui_update_timer = None

    def on_closing(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –æ–∫–Ω–∞."""
        print("–ó–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
        if self.is_recording:
            self.stop_recording() # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å, –µ—Å–ª–∏ –∏–¥–µ—Ç
        else:
            if self.processing_thread is not None and self.processing_thread.is_alive():
                print("–û—Ç–ø—Ä–∞–≤–∫–∞ –º–∞—Ä–∫–µ—Ä–∞ –∫–æ–Ω—Ü–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏...")
                self.audio_queue.put(QUEUE_END_MARKER)
                # –ù–µ –∂–¥–µ–º –∑–¥–µ—Å—å –¥–æ–ª–≥–æ, –ø—Ä–æ—Å—Ç–æ –¥–∞–µ–º —à–∞–Ω—Å –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è
                self.processing_thread.join(timeout=1.0)
        
        self.stop_gui_updater() # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä GUI
        self.root.destroy()     # –ó–∞–∫—Ä—ã—Ç–∏–µ –æ–∫–Ω–∞

if __name__ == "__main__":
    whisper_model = None
    feauture_extractor = None
    tokenizer = None

    # whisper-tiny
    # feauture_extractor = WhisperFeatureExtractor.from_pretrained("models--openai--whisper-tiny/snapshots/169d4a4341b33bc18d8881c4b69c2e104e1cc0af")
    # whisper_model = WhisperForConditionalGeneration.from_pretrained("models--openai--whisper-tiny/snapshots/169d4a4341b33bc18d8881c4b69c2e104e1cc0af")
    # tokenizer = WhisperTokenizer.from_pretrained("models--openai--whisper-tiny/snapshots/169d4a4341b33bc18d8881c4b69c2e104e1cc0af", language = "russian", task="transcribe")

    # whisper-large-v3-turbo
    # feauture_extractor = WhisperFeatureExtractor.from_pretrained("models--openai--whisper-large-v3-turbo/snapshots/41f01f3fe87f28c78e2fbf8b568835947dd65ed9")
    # whisper_model = WhisperForConditionalGeneration.from_pretrained("models--openai--whisper-large-v3-turbo/snapshots/41f01f3fe87f28c78e2fbf8b568835947dd65ed9")
    # tokenizer = WhisperTokenizer.from_pretrained("models--openai--whisper-large-v3-turbo/snapshots/41f01f3fe87f28c78e2fbf8b568835947dd65ed9", language = "russian", task="transcribe")
    
    # whisper_model.to(device)

    root = tk.Tk()

    if whisper_model:
        app = AudioApp(root, model, feauture_extractor, whisper_model, tokenizer) # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Whisper
    else:
        app = AudioApp(root, model) # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –º–æ—è
    
    root.protocol("WM_DELETE_WINDOW", app.on_closing) # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –æ–∫–Ω–∞
    root.mainloop()